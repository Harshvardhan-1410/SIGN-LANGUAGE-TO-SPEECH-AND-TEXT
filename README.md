# SIGN-LANGUAGE-TO-SPEECH-AND-TEXT
It is the model which detects the sign language (i.e, symbols using fingers, palm) shown by the user and converts it to text and speech(AI voice)
This hand gesture translator project converts sign language (hand gestures) to both text and speech through computer vision and machine learning. It's particularly beneficial for people with hearing or speech disabilities to be able to communicate easily.

## Features

- Hand gesture detection in real-time via webcam
- Classification of gestures via trained ML model
- Display of corresponding text for detected gestures
- Voice output via text-to-speech (TTS)
- Easy-to-use GUI created using Tkinter


## Tech Stack

- Tkinter(Python)
- MediaPipe
- Random Forest Classifier(sklearn)
- OpenCV,MediaPipe
- CSV (landmarks + labels) 
- Pickle            
- pyttsx3 (offline TTS)


## Future Improvements
- Add support for multiple hands 
- Expanding gesture dataset
- Include sentence construction from sequences
- Add language translation feature








